{
  "portfolioInfo": {
    "title": "Juan Pablo Carrascal - Projects Portfolio",
    "subtitle": "Interactive Media & Digital Arts Portfolio",
    "contact": {
      "email": "jp@jpcarrascal.com",
      "website": "jpcarrascal.github.io",
      "period": "2010-2024"
    }
  },
  "projects": [
    {
      "id": "spacebarman",
      "title": "Spacebarman",
      "year": "2010 - Present",
      "authors": "JP Carrascal",
      "tags": ["Electronic Music", "Live Performance", "Interactive Installation"],
      "subtitle": "Electronic / Experimental music project",
      "description": "Spacebarman is an electronic/experimental music project, the musical alter-ego of JP Carrascal, a Colombian-Spanish artist and researcher. Its music is the result of an unholy mixture of dark electro pop, industrial, drum & bass and shoegaze, equally dance floor and moshpit-friendly. Its concerts are a digital art laboratory, where interactive devices and reactive visuals developed with the help of AI create an immersive experience for the audience.",
      "medium": "Electronic music: live performances with interactive visuals and AI",
      "exhibition": ["Almagro Film Festival, Spain, 2025", "Festival Acoustic Vell, Girona, Spain, 2025", "ManasiaHub, Bucharest, Romania, 2025", "Sofia Live Club, Sofia, Bulgaria, 2025", "Madame Claude, Berlin, 2024"],
      "image": "../projects/spacebarman/images/spacebarman-madameclaude.jpg",
      "selected": true
    },
    {
      "id": "a-sense-of-surrounding",
      "title": "A Sense Of Surrounding",
      "year": 2024,
      "authors": "JP Carrascal, Tom DeMajo",
      "tags": ["Interactive Installation"],
      "subtitle": "Participatory soundscape to promote environmental awareness. Presented at Ars Electronica 2024 (Linz, Austria). Supported by ArtEO.",
      "description": "A Sense of Surrounding is an participatory soundscape installation designed to promote environmental awareness through immersive audio experiences. This collaborative project was presented at the prestigious Ars Electronica 2024 festival in Linz, Austria, one of the world's most important festivals for digital arts and electronic music.\n\nThe installation creates an interactive environment where participants can engage with environmental themes through carefully crafted soundscapes. The work leverages the power of audio to create emotional connections with environmental issues, encouraging deeper reflection on humanity's relationship with nature. This project was supported by ArtEO (www.arteo.earth), an organization dedicated to promoting environmental awareness through artistic practices.",
      "medium": "Digital: collaborative interactive sound installation",
      "exhibition": ["Ars Electronica 2024, Linz, Austria"],
      "publication": ["Juan Pablo Carrascal and Tom DeMajo. Conference Proceedings of CHIME One Day Workshop 2023, The Open University, Milton Keynes, 4 December 2023."],
      "image": "../projects/a-sense-of-surrounding/images/main.jpg",
      "selected": true
    },
    {
      "id": "intangible",
      "title": "InTangible",
      "year": 2023,
      "authors": "JP Carrascal, Ina Ghita",
      "tags": ["Art Installation"],
      "subtitle": "A Reflection on Digital vs. Physical Co-Ownership",
      "description": "InTangible is an art project that explores the complex relationships between digital and physical ownership in contemporary society. Through mixed media installation work, this project examines how we understand possession, value, and co-ownership in an increasingly digital world.\n\nThe work challenges traditional notions of ownership by creating scenarios where digital and physical objects intersect, questioning what it means to truly \"own\" something in the digital age. Through interactive elements and visual representations, participants are invited to consider how technology reshapes our understanding of property and shared resources.",
      "medium": "Mixed media: woven canvas, recycled 3D printer, cloud-hosted application",
      "themes": "Digital Ownership, NFTs, Co-ownership",
      "exhibition": ["TEI Art Exhibition, Warsaw, Poland, 2023."],
      "publication": ["Juan Pablo Carrascal and Ina Ghita. 2023. InTangible: A Reflection On Digital vs. Physical Co-Ownership. In Proceedings of the Seventeenth International Conference on Tangible, Embedded, and Embodied Interaction (TEI '23). Association for Computing Machinery, New York, NY, USA, Article 61, 1–2. DOI: 10.1145/3569009.3576187"],
      "image": "../projects/intangible/images/intangible01.jpg",
      "selected": true
    },
    {
      "id": "hootbeat",
      "title": "HootBeat",
      "year": 2022,
      "authors": "JP Carrascal",
      "tags": ["Live Performance", "Wearable Technology"],
      "subtitle": "A Platform for MIDI-Controlled Lighting Wearables",
      "description": "HootBeat is a comprehensive platform for MIDI-controlled lighting wearable devices that bridges technology, performing arts, and fashion. The system enables musicians to wear lighting devices that respond dynamically to their musical performance, creating synchronized light shows that enhance live performances.\n\nThe platform consists of custom-designed LED goggles equipped with ESP32 microcontrollers for wireless BLE-MIDI communication, a custom pedalboard controller, trigger-to-MIDI interfaces for acoustic drums, and cloud-based audience interaction capabilities. The system has been used in live performances by Spacebarman, including shows at Barcelona's Festes de Maig.",
      "medium": "Mixed media: custom hardware and sofware, cloud-hosted application",
      "exhibition": ["Live performances by Spacebarman"],
      "image": "../projects/hootbeat/images/hootbeat-spacebarman.png",
      "selected": true
    },
    {
      "id": "count-me-in",
      "title": "Count-Me-In",
      "year": 2022,
      "authors": "JP Carrascal",
      "tags": ["Audience Participation", "Live Performance"],
      "subtitle": "A collaborative music step sequencer for audience participation",
      "description": "Modern musical events create a boundary between performers and the audience, with only the former playing an active role. Count-Me-In is a collaborative music sequencer that uses a distributed Web architecture to promote audience participation in music performances, installations, and other related contexts.\n\nCount-Me-In uses a step-sequencer design to reduce the negative effects of network latency on the participants' experience. The web-based interface allows audience members to contribute to the musical creation in real-time, breaking down traditional performance barriers.",
      "medium": "Digital: collaborative interactive sound installation",
      "exhibition": ["SMC demo session, Saint Etienne, France, 2022.", "Live performances by Spacebarman"],
      "publication": ["Carrascal, Juan Pablo. (2022, June 7). Count-Me-In: A Collaborative Step Sequencer for Audience Participation. Proceedings of the 2022 Sound and Music Computing Conference (SMC22). DOI: 10.5281/zenodo.6573453", "Carrascal, Juan Pablo. (2022, June 7). Social / Musical Gaming with Count-Me-in (demo). Proceedings of the 2022 Sound and Music Computing Conference (SMC22). DOI: 10.5281/zenodo.6576041"],
      "image": "../projects/count-me-in/images/main.jpg",
      "selected": true
    },
    {
      "id": "ble-midi-glove",
      "title": "BLE-MIDI Glove Controller",
      "year": 2021,
      "authors": "JP Carrascal",
      "tags": [],
      "subtitle": "A Bluetooth LE-MIDI-based glove controller for musical performance",
      "description": "The BLE-MIDI Glove Controller is a wearable musical interface that combines Bluetooth Low Energy (BLE) technology with MIDI communication protocols. This project represents a simple approach to gestural music control, allowing performers to manipulate sound through natural hand movements and finger gestures.\n\nBuilt using modern BluetoothLE-MIDI technology, the glove controller offers freedom of movement while maintaining reliable, low-latency communication with digital audio workstations and synthesizers. The device incorporates inertial movement unit (IMU) sensors to capture hand motion and middle finger positioning, translating these into expressive musical parameters.\n\nThis glove has been used in live performances by Spacebarman, demonstrating its practical application in professional musical contexts.",
      "medium": "Custom hardware and software, textile integration",
      "exhibition": ["Live performances by Spacebarman"],
      "image": "../projects/ble-midi-glove/images/main.jpg",
      "selected": true
    },
    {
      "id": "momc-controller",
      "title": "MoMc Modular MIDI Controller",
      "year": 2021,
      "authors": "JP Carrascal",
      "tags": ["Live Performance", "Studio Control"],
      "subtitle": "Arduino-based modular MIDI pedal controller",
      "description": "The MoMc (Modular MIDI Controller) is an Arduino-based pedal controller designed for musicians who need flexible, programmable control over their digital audio setup. This modular approach allows for customizable configurations based on specific performance needs and musical contexts.\n\nBuilt using Arduino microcontroller technology, the MoMc controller provides reliable MIDI communication with various musical devices and software. The modular design enables musicians to configure the controller according to their specific requirements, making it suitable for diverse musical applications from live performance to studio work.",
      "medium": "Custom hardware and software",
      "exhibition": ["Live performances by Spacebarman"],
      "image": "../projects/momc-controller/images/main.jpg",
      "selected": false
    },
    {
      "id": "lockdown",
      "title": "Lockdown",
      "year": 2020,
      "authors": "JP Carrascal",
      "tags": [],
      "subtitle": "An interactive VR videoclip for Spacebarman's song \"Lockdown\". Built with WebVR/WebXR, best experienced with an Oculus Quest.",
      "description": "Lockdown is an innovative interactive music video created for Spacebarman's song \"Lockdown\", developed during the 2020 global pandemic. This project represents a pioneering approach to musical visualization, combining virtual reality technology with artistic expression to create an immersive audiovisual experience.\n\nBuilt using WebVR/WebXR technologies, the project is accessible through web browsers while delivering a fully immersive experience, particularly when viewed with VR headsets like the Oculus Quest. The browser-based approach ensures accessibility while pushing the boundaries of what's possible with web-based virtual reality.",
      "medium": "Digital: WebVR/WebXR virtual reality application",
      "exhibition": ["WebVR experience available at https://jpcarrascal.com/lockdown-vr/"],
      "image": "../projects/lockdown/images/main.jpg",
      "selected": false
    },
    {
      "id": "blesync",
      "title": "BLESync",
      "year": 2019,
      "authors": "JP Carrascal",
      "tags": ["Music Production", "Live Performance"],
      "subtitle": "A Bluetooth device for synchronizing tap-tempo guitar pedals to computer DAWs",
      "description": "BLESync is a specialized Bluetooth device designed to bridge the gap between traditional guitar effects pedals and modern digital audio workstations (DAWs). The device enables guitarists to synchronize their tap-tempo pedals with computer-based music production software, creating seamless integration between analog and digital musical workflows.\n\nThis tool addresses a common challenge in modern music production where musicians want to maintain the tactile feel of physical pedals while benefiting from the precision and capabilities of digital audio systems. BLESync ensures accurate timing synchronization, crucial for professional music production and live performance scenarios.",
      "medium": "Custom hardware and software, acrylic enclosure",
      "publication": ["Carrascal, Juan Pablo. (2019, June 26). BLESync: A Bluetooth Device for Synchronizing Tap-Tempo Guitar Pedals to Computer DAWs. Proceedings of the 2019 Sound and Music Computing Conference (SMC19). DOI: zenodo.3755756"],
      "image": "../projects/blesync/images/main.jpg",
      "selected": false
    },
    {
      "id": "magicscroll",
      "title": "MagicScroll",
      "year": 2018,
      "authors": "Antonio Gomes, Lahiru Lakmal Priyadarshana, Aaron Visser, Juan Pablo Carrascal, Roel Vertegaal",
      "tags": ["Human-Computer Interaction", "Shape-Changing Interfaces"],
      "subtitle": "A rollable display device with flexible screen area and gestural input",
      "description": "We present MagicScroll, a rollable tablet with 2 concatenated flexible multitouch displays, actuated scrollwheels and gestural input. When rolled up, MagicScroll can be used as a rolodex, smartphone, expressive messaging interface or gestural controller. When extended, it provides full access to its 7.5\" high-resolution multitouch display, providing the display functionality of a tablet device.\n\nWe believe that the cylindrical shape in the rolled-up configuration facilitates gestural interaction, while its shape changing and input capabilities allow the navigation of continuous information streams and provide focus plus context functionality. We investigated the gestural affordances of MagicScroll in its rolled-up configuration by means of an elicitation study.",
      "medium": "Custom hardware and software, recycled flexible screens.",
      "publication": ["Antonio Gomes, Lahiru Lakmal Priyadarshana, Aaron Visser, Juan Pablo Carrascal, Roel Vertegaal. (2018). Magicscroll: a rollable display device with flexible screen real estate and gestural input. DOI: 10.1145/3242587.3242652"],
      "image": "../projects/magicscroll/images/main.jpg",
      "selected": true
    },
    {
      "id": "ar-wall",
      "title": "AR Wall",
      "year": 2018,
      "authors": "JP Carrascal",
      "tags": ["Research Presentation", "Knowledge Sharing"],
      "subtitle": "An augmented reality installation for sharing UX research results at Microsoft",
      "description": "AR Wall is an innovative augmented reality installation designed to share UX research project results at Microsoft. This interactive wall transforms traditional presentation methods by using AR technology to create an immersive and engaging way to communicate research findings and insights.\n\nThe project leverages augmented reality to overlay digital information onto a physical wall space, allowing viewers to interact with research data, visualizations, and findings in a spatial and intuitive manner. This approach makes complex UX research results more accessible and engaging for diverse audiences within the organization.",
      "medium": "Mixed: physical installation with augmented reality",
      "exhibition": ["Microsoft campus, Building 18, Redmond, WA, USA."],
      "image": "../projects/ar-wall/images/main.jpg",
      "selected": false
    },
    {
      "id": "haptics-cylindrical",
      "title": "Haptics on Cylindrical Displays",
      "year": 2017,
      "authors": "Juan Pablo Carrascal, Roel Vertegaal",
      "tags": ["Human Perception", "Haptic Illusions"],
      "subtitle": "Effects of Tactile Feedback on the Perception of Virtual Shapes on Non-Planar DisplayObjects",
      "description": "In this paper, we report on a study investigating a novel haptic illusion for altering the perception of 3D shapes using a non-planar screen and vibrotactile friction. In our study, we presented an image of a rectangular prism on a cylindrical and a flat display. Participants were asked to move their index finger horizontally along the surface of the displays towards the edge of the rectangular prism.\n\nParticipants were asked whether they were experiencing a flat, cylindrical or rectangular shape. In one condition, a vibrotactile stimulus simulated increasing friction towards the visible edge of the rectangular prism, with a sudden drop-off when this edge was crossed by the finger. Results suggest that presenting an image of a rectangular prism, and applying vibrotactile friction, particularly on a cylindrical display, significantly increased participant ratings stating that they were experiencing a physical rectangular shape.",
      "medium": "Custom hardware and software, recycled flexible screens and vibrotactile actuators.",
      "publication": ["Juan Pablo Carrascal, Roel Vertegaal. (2017). Effects of tactile feedback on the perception of virtual shapes on non-planar DisplayObjects. DOI: 10.1145/3025453.3025788"],
      "image": "../projects/haptics-cylindrical/images/main.jpg",
      "selected": true
    },
    {
      "id": "reflex",
      "title": "ReFlex",
      "year": 2016,
      "authors": "Paul Strohmeier, Jesse Burstyn, Juan Pablo Carrascal, Vincent Levesque, Roel Vertegaal",
      "tags": ["Shape-Changing Interfaces", "Mobile Computing"],
      "subtitle": "A flexible smartphone with active haptic feedback for bend input",
      "description": "ReFlex is a flexible smartphone with bend input and active haptic feedback. ReFlex's features allow the introduction of sensations such as friction or resistance. We report results from an experiment using ReFlex in a targeting task, as well as initial users' reactions to the prototype.\n\nWe explore both absolute and relative tactile haptic feedback, paired with two types of bend input mappings: position-control and rate-control. We observed that position-controlled cursors paired well with relative bend feedback, while rate-controlled cursors paired well with absolute bend feedback to indicate targets.\n\nWe also explored an eyes-free condition. Results suggest that while eyes-free, haptic feedback conditions were more error-prone than visual-only conditions, the size of the error was relatively small, and users were able to complete the task in all cases.",
      "medium": "Custom hardware and software, recycled flexible screens, vibrotactile actuators",
      "publication": ["Paul Strohmeier, Jesse Burstyn, Juan Pablo Carrascal, Vincent Levesque, Roel Vertegaal. (2016). Reflex: A flexible smartphone with active haptic feedback for bend input. DOI: 10.1145/2839462.2839494"],
      "image": "../projects/reflex/images/main.jpg",
      "selected": true
    },
    {
      "id": "whammyphone",
      "title": "Whammyphone",
      "year": 2016,
      "authors": "Antonio Gomes, Lahiru Priyadarshana, Juan Pablo Carrascal, Roel Vertegaal",
      "tags": ["Tangible Music Interfaces", "Audio Manipulation"],
      "subtitle": "Exploring tangible audio manipulation using bend input on a flexible smartphone",
      "description": "We present WhammyPhone, a novel audio interface that supports physical manipulation of digital audio through bend gestures. WhammyPhone combines a high-resolution flexible display, bend sensors, and a set of intuitive interaction techniques that enable novice users to manipulate sound in a tangible fashion.\n\nWith WhammyPhone, bend gestures can control both discrete (e.g. triggering a note) and continuous parameters (e.g. pitch bend). We showcase application scenarios that leverage the unique input modalities of WhammyPhone and discuss its potential for digital audio manipulation.",
      "medium": "Custom hardware and software, recycled flexible screens",
      "publication": ["Antonio Gomes, Lahiru Priyadarshana, Juan Pablo Carrascal, Roel Vertegaal. (2016). Whammyphone: Exploring tangible audio manipulation using bend input on a flexible smartphone. DOI: 10.1145/2984751.2985742"],
      "image": "../projects/whammyphone/images/main.jpg",
      "selected": false
    },
    {
      "id": "shape-emotions",
      "title": "Shape Changes for Conveying Emotions",
      "year": 2016,
      "authors": "Paul Strohmeier, Juan Pablo Carrascal, Bernard Cheng, Margaret Meban, Roel Vertegaal",
      "tags": ["Affective Computing", "Shape-Based Communication"],
      "subtitle": "An evaluation of shape changes for conveying emotions",
      "description": "In this paper, we explore how shape changing interfaces might be used to communicate emotions. We present two studies, one that investigates which shapes users might create with a 2D flexible surface, and one that studies the efficacy of the resulting shapes in conveying a set of basic emotions.\n\nResults suggest that shape parameters are correlated to the positive or negative character of an emotion, while parameters related to movement are correlated with arousal level. In several cases, symbolic shape expressions based on clear visual metaphors were used.\n\nResults from our second experiment suggest participants were able to recognize emotions given a shape with a good accuracy within 28% of the dimensions of the Circumplex Model. We conclude that shape and shape changes of a 2D flexible surface indeed appear able to convey emotions in a way that is worthy of future exploration.",
      "medium": "Flexible textile augmented with bend sensors, custom software",
      "publication": ["Paul Strohmeier, Juan Pablo Carrascal, Bernard Cheng, Margaret Meban, Roel Vertegaal. (2016). An evaluation of shape changes for conveying emotions. DOI: 10.1145/2858036.2858537"],
      "image": "../projects/shape-emotions/images/main.jpg",
      "selected": false
    },
    {
      "id": "bluemo",
      "title": "BlueMO",
      "year": 2016,
      "authors": "JP Carrascal",
      "tags": ["Music Production", "Wireless Controllers"],
      "subtitle": "Bluetooth LE to MIDI/OSC translator for Mac OS X",
      "description": "BlueMO is a Bluetooth Low Energy to MIDI/OSC translator application designed specifically for Mac OS X. This utility application enables seamless communication between Bluetooth LE devices and music software, allowing wireless controllers and sensors to interact with digital audio workstations and other musical applications.\n\nThe application serves as a bridge between the growing ecosystem of Bluetooth LE devices and traditional music production software, translating wireless sensor data into MIDI messages or OSC (Open Sound Control) commands that can be understood by music software. This opens up new possibilities for wireless musical controllers and interactive performance systems.",
      "medium": "Software",
      "image": "../projects/bluemo/images/main.jpg",
      "selected": false
    },
    {
      "id": "bicing-spider",
      "title": "Bicing Spider",
      "year": 2011,
      "authors": "JP Carrascal",
      "tags": [],
      "subtitle": "An experiment on Web data scraping and interactive visualization using Quartz Composer",
      "description": "An experiment on Web data scraping and interactive visualization using Quartz Composer. This project explores real-time data visualization techniques for public bicycle sharing system data.",
      "medium": "Digital.",
      "image": "../projects/bicing-spider/images/main.jpg",
      "selected": false
    },
    {
      "id": "trackpad-controller",
      "title": "Trackpad Controller",
      "year": 2010,
      "authors": "JP Carrascal",
      "tags": [],
      "subtitle": "Max for Live device for using a Macbook trackpad as an Ableton Live controller",
      "description": "Max for Live device for using a Macbook trackpad as an Ableton Live controller. Transforms the laptop's built-in trackpad into a musical performance interface.",
      "medium": "Interactive media",
      "image": "../projects/trackpad-controller/images/main.jpg",
      "selected": false
    },
    {
      "id": "random-controller",
      "title": "Random Controller",
      "year": 2010,
      "authors": "JP Carrascal",
      "tags": [],
      "subtitle": "A simple experiment on using dice-rolling as a control source",
      "description": "A simple experiment on using dice-rolling as a control source for musical parameters, exploring chance operations in electronic music performance.",
      "medium": "Mixed media: interactive experience built with recycled lamp and dice and sofware",
      "image": "../projects/random-controller/images/main.jpg",
      "selected": false
    },
    {
      "id": "multitouchmixer",
      "title": "Multitouch Mixer",
      "year": 2010,
      "authors": "JP Carrascal, Sergi Jordà",
      "tags": [],
      "subtitle": "Interface for Audio Mixing with Multitouch Technology (MSc thesis)",
      "description": "Interface for Audio Mixing with Multitouch Technology (MSc thesis). Explores how multitouch interfaces can enhance traditional audio mixing workflows.",
      "medium": "Interactive media: custom software running on ReacTable platform.",
      "publication": ["Carrascal, Juan Pablo, and Sergi Jordà. 2011. \"Multitouch Interface for Audio Mixing.\" In Proceedings of New Interfaces for Musical Expression (NIME '11)."],
      "image": "../projects/multitouchmixer/images/multitouch-frame.jpg",
      "selected": true
    },
    {
      "id": "augmented-guitar",
      "title": "Augmented Guitar",
      "year": 2010,
      "authors": "JP Carrascal",
      "tags": [],
      "subtitle": "Electronic enhancement for electric guitars using motion sensors",
      "description": "Electronic enhancement for electric guitars using motion sensors. My take on the old theme of augmenting electric guitars with electronics to expand their expressive capabilities.",
      "medium": "Mixed media: custom hardware and sofware",
      "exhibition": ["Live performances by Spacebarman"],
      "image": "../projects/augmented-guitar/images/main.jpg",
      "selected": true
    }
  ]
}